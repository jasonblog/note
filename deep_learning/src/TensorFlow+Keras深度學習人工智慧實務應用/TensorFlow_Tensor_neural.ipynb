{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y= relu ( (X․W ) + b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y:\n",
      "[[ 0.    0.28]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "\n",
    "W = tf.Variable([[-0.5,-0.2 ],\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "                         \n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "    \n",
    "XWb =tf.matmul(X,W)+b\n",
    "\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:')    \n",
    "    print(sess.run(XWb ))    \n",
    "    print('y:')    \n",
    "    print(sess.run(y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y= sigmoid ( (X․W ) + b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y:\n",
      "[[ 0.41095957  0.56954622]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "\n",
    "W = tf.Variable([[-0.5,-0.2 ],\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "\n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "\n",
    "XWb=tf.matmul(X,W)+b\n",
    "\n",
    "y=tf.nn.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:')    \n",
    "    print(sess.run(XWb))    \n",
    "    print('y:')    \n",
    "    print(sess.run(y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 以亂數產生Weight(W)與bais(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[ 0.29273087  0.51423353]]\n",
      "W:\n",
      "[[-1.01236403  0.18786868]\n",
      " [-0.02965575  1.90990174]\n",
      " [ 1.54748416 -0.1023059 ]]\n",
      "y:\n",
      "[[ 0.50084782  0.930439  ]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('b:')\n",
    "    print(sess.run(b ))    \n",
    "    print('W:')\n",
    "    print(sess.run(W ))\n",
    "    print('y:')\n",
    "    print(sess.run(y ))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-0.11026619 -0.17966861]]\n",
      "W:\n",
      "[[ 0.80971348  0.05690608]\n",
      " [ 0.43664974  0.64918804]\n",
      " [-2.14770865  1.89645529]]\n",
      "y:\n",
      "[[ 0.          0.73151356]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    (_b,_W,_y)=sess.run((b,W,y))\n",
    "    print('b:')\n",
    "    print(_b)\n",
    "    print('W:')\n",
    "    print(_W)\n",
    "    print('y:')\n",
    "    print(_y)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-1.00988698 -0.90781182]]\n",
      "W:\n",
      "[[ 0.77819425  0.74534345]\n",
      " [ 0.62385881 -0.30757746]\n",
      " [ 0.84864932  1.10149086]]\n",
      "X:\n",
      "[[ 0.40000001  0.2         0.40000001]]\n",
      "y:\n",
      "[[ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder(\"float\", [None,3])\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2,0.4]])\n",
    "    (_b,_W,_X,_y)=sess.run((b,W,X,y),feed_dict={X:X_array})\n",
    "    print('b:')\n",
    "    print(_b)    \n",
    "    print('W:')\n",
    "    print(_W)\n",
    "    print('X:')\n",
    "    print(_X)\n",
    "    print('y:')\n",
    "    print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[-0.62594283 -1.53080451  0.20968008  0.48862299 -0.98033726  1.56872106\n",
      "  0.34392843 -0.32248533 -1.38410163 -0.8074798   0.06213726  0.41173849\n",
      " -0.79638833  0.07239912 -1.5461148  -1.4486984   0.5450505   0.37378398\n",
      " -0.23069905 -0.26489291 -1.30195487 -0.18677172  0.50207907 -1.00787842\n",
      "  0.56418502  0.51869804 -1.74017227 -2.36948991  0.98451078  0.93969965]\n"
     ]
    }
   ],
   "source": [
    "ts_norm = tf.random_normal([1000])\n",
    "with tf.Session() as session:\n",
    "    norm_data=ts_norm.eval()\n",
    "print(len(norm_data))\n",
    "print(norm_data[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXpIaZ9BLUuP+D5+kH0xzUw4rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23c7b875e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(norm_data)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[ 0.01747627 -1.21260917]]\n",
      "W:\n",
      "[[-0.31123674  2.33802915]\n",
      " [ 1.30897081  0.78729075]\n",
      " [-0.47610989  0.79479092]]\n",
      "X:\n",
      "[[ 0.40000001  0.2         0.40000001]\n",
      " [ 0.30000001  0.40000001  0.5       ]\n",
      " [ 0.30000001 -0.40000001  0.5       ]]\n",
      "y:\n",
      "[[ 0.49108386  0.54933321]\n",
      " [ 0.55221856  0.55010903]\n",
      " [ 0.30205354  0.39443171]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder(\"float\", [None,3])\n",
    "y=tf.nn.sigmoid(tf.matmul(X,W)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2 ,0.4],\n",
    "                        [0.3,0.4 ,0.5],\n",
    "                        [0.3,-0.4,0.5]])    \n",
    "    (_b,_W,_X,_y)=sess.run((b,W,X,y),feed_dict={X:X_array})\n",
    "    print('b:')\n",
    "    print(_b)    \n",
    "    print('W:')\n",
    "    print(_W)\n",
    "    print('X:')\n",
    "    print(_X)\n",
    "    print('y:')\n",
    "    print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(output_dim,input_dim,inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.1       ]\n",
      " [ 0.30000001  0.40000001  0.5         0.30000001]\n",
      " [ 0.30000001 -0.40000001  0.5         0.2       ]]\n",
      "y:\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.62641364  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "\n",
    "y=layer(output_dim=3,input_dim=4,inputs=X,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2 ,0.4,0.1],\n",
    "                        [0.3,0.4 ,0.5,0.3],\n",
    "                        [0.3,-0.4,0.5,0.2]])    \n",
    "    (_X,_y)=sess.run((X,y),feed_dict={X:X_array})\n",
    "    print('X:')\n",
    "    print(_X)\n",
    "    print('y:')\n",
    "    print(_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.5       ]]\n",
      "hidden Layer h:\n",
      "[[ 0.75357503  0.          0.        ]]\n",
      "output Layer y:\n",
      "[[ 0.94026488 -1.73186076]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "h=layer(output_dim=3,input_dim=4,inputs=X,\n",
    "        activation=tf.nn.relu)\n",
    "y=layer(output_dim=2,input_dim=3,inputs=h)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2 ,0.4,0.5]])    \n",
    "    (layer_X,layer_h,layer_y)= \\\n",
    "            sess.run((X,h,y),feed_dict={X:X_array})\n",
    "    print('input Layer X:')\n",
    "    print(layer_X)\n",
    "    print('hidden Layer h:')\n",
    "    print(layer_h)\n",
    "    print('output Layer y:')\n",
    "    print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_debug(output_dim,input_dim,inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs,W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.5       ]]\n",
      "W1:\n",
      "[[-0.09314669 -0.36818534 -0.18249217]\n",
      " [-1.04823184  0.52818018  0.13691556]\n",
      " [ 0.12561655 -0.6045742  -0.31484881]\n",
      " [-1.00719798 -0.73655051  0.18927324]]\n",
      "b1:\n",
      "[[-0.20122531 -0.91442204  0.86802369]]\n",
      "hidden Layer h:\n",
      "[[ 0.          0.          0.79110706]]\n",
      "W2:\n",
      "[[-0.4516722   0.25634161]\n",
      " [-0.41245425 -0.3368454 ]\n",
      " [ 0.35034841  0.00755273]]\n",
      "b2:\n",
      "[[-1.59815466 -0.14974241]]\n",
      "output Layer y:\n",
      "[[-1.32099152 -0.14376739]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "h,W1,b1=layer_debug(output_dim=3,input_dim=4,inputs=X,\n",
    "                    activation=tf.nn.relu)\n",
    "y,W2,b2=layer_debug(output_dim=2,input_dim=3,inputs=h)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2 ,0.4,0.5]])    \n",
    "    (layer_X,layer_h,layer_y,W1,b1,W2,b2)= \\\n",
    "             sess.run((X,h,y,W1,b1,W2,b2),feed_dict={X:X_array})\n",
    "    print('input Layer X:')\n",
    "    print(layer_X)\n",
    "    print('W1:')\n",
    "    print(  W1)    \n",
    "    print('b1:')\n",
    "    print(  b1)    \n",
    "    print('hidden Layer h:')\n",
    "    print(layer_h)    \n",
    "    print('W2:')\n",
    "    print(  W2)    \n",
    "    print('b2:')\n",
    "    print(  b2)    \n",
    "    print('output Layer y:')\n",
    "    print(layer_y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
